# BBC Scraper Project

## Overview
This project involves scraping data from the BBC using Airflow, Selenium, and Beautiful Soup. The scraped data is loaded into MongoDB for storage and analyzed with Pandas.

## Components
1. **Airflow:** Manages workflows and schedules scraping tasks.
2. **Selenium:** Automates web browser to scrape dynamic content.
3. **Beautiful Soup:** Parses HTML content to extract data.
4. **MongoDB:** NoSQL database for storing scraped data.
5. **Pandas:** Performs data analysis and manipulation.

## Analysis
The `analysis` folder contains scripts and notebooks demonstrating data cleaning, transformation, and exploratory data analysis.

## Technical Details
- Docker setup for containerization and consistent deployment.
- `docker-compose.yml` manages services ensuring smooth operation.
- Dependencies managed via `requirements.txt`.

For more details: [Mounir Houl Linkedin](https://www.linkedin.com/in/mounir-houl/).
